{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204f556b-4d61-4b1b-a23e-4747f3637ebf",
   "metadata": {},
   "source": [
    "## Exercise 1: Anomaly Detection\n",
    "##### Objective: Implement an anomaly detection system using Python libraries.\n",
    "#### Tasks:\n",
    "#### 1) Data Collection:\n",
    "* Use a publicly available dataset (e.g., KDD Cup, Credit Card Fraud Detection) or generate synthetic data for anomaly detection.\n",
    "* Load the dataset using pandas and perform initial exploratory data analysis (EDA).\n",
    "#### 2) Data Preprocessing:\n",
    "* Handle missing values and outliers in the dataset.\n",
    "* Normalize or standardize features as necessary.\n",
    "#### 3) Anomaly Detection Techniques:\n",
    "* Implement at least two different anomaly detection algorithms, such as:\n",
    "* Statistical Method: Use Z-score or IQR for univariate anomaly detection.\n",
    "* Machine Learning Method: Implement Isolation Forest or One-Class SVM from scikit-learn.\n",
    "* Deep Learning Method: Build an autoencoder for anomaly detection.\n",
    "#### 4) Model Evaluation:\n",
    "* Split the dataset into training and testing sets.\n",
    "* Evaluate the performance of the models using metrics such as precision, recall, and F1-score.\n",
    "* Visualize the results using confusion matrices and ROC curves.\n",
    "#### 5) Visualization:\n",
    "* Use matplotlib or seaborn to visualize the detected anomalies against the normal data points.\n",
    "* Create plots that showcase the distribution of features and the anomalies.\n",
    "#### 6) Reporting Findings:\n",
    "* Summarize the detection results, including the number of detected anomalies and the effectiveness of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f9abc0-8bd2-4ecf-bd87-84e7d2cbe576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Загрузка данных (например, датасет о мошенничестве с кредитными картами)\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00a7e1c-dea5-48b7-8a44-2b016eb6bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка пропущенных значений\n",
    "data.isnull().sum()\n",
    "\n",
    "# Нормализация количественных признаков\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop('Class', axis=1))\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test = data_scaled[:200000], data_scaled[200000:]\n",
    "y_train, y_test = data['Class'][:200000], data['Class'][200000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1330028-b4f8-4d45-9b6f-6b95fa5cd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод машинного обучения: Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "y_pred_iso = iso_forest.predict(X_test)\n",
    "y_pred_iso = [1 if x == -1 else 0 for x in y_pred_iso]\n",
    "\n",
    "# Метод машинного обучения: One-Class SVM\n",
    "svm = OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.1)\n",
    "svm.fit(X_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_svm = [1 if x == -1 else 0 for x in y_pred_svm]\n",
    "\n",
    "# Отчёты о метриках\n",
    "print(\"Isolation Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_iso))\n",
    "\n",
    "print(\"One-Class SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42716c-49f3-4fa5-9daf-fc2b72150707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрицы ошибок\n",
    "conf_matrix_iso = confusion_matrix(y_test, y_pred_iso)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "sns.heatmap(conf_matrix_iso, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Isolation Forest\")\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
    "plt.title(\"Confusion Matrix - One-Class SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a54946-9aca-4807-a41f-e02b8b306fcb",
   "metadata": {},
   "source": [
    "## Exercise 2: Time Series Analysis\n",
    "##### Objective: Analyze and forecast a time series dataset using Python libraries.\n",
    "#### Tasks:\n",
    "#### Data Collection:\n",
    "* Select a time series dataset (e.g., stock prices, weather data, or sales data).\n",
    "* Load the dataset using pandas and perform initial EDA.\n",
    "#### Data Preprocessing:\n",
    "* Handle any missing values in the time series data.\n",
    "* Resample the data to a uniform time interval if necessary (e.g., daily, weekly).\n",
    "#### Exploratory Data Analysis:\n",
    "* Visualize the time series data using line plots to identify trends, seasonality, and patterns.\n",
    "* Decompose the time series into trend, seasonality, and residuals using seasonal decomposition.\n",
    "#### Modeling:\n",
    "* Implement forecasting techniques, such as:\n",
    "* ARIMA Model: Fit an ARIMA model to the data and determine the appropriate parameters (p, d, q).\n",
    "* Exponential Smoothing: Use Holt-Winters method for forecasting seasonal data.\n",
    "* Machine Learning Approach: Implement a model using scikit-learn (e.g., Random Forest, LSTM for deep learning).\n",
    "#### Model Evaluation:\n",
    "* Split the dataset into training and testing sets.\n",
    "* Evaluate the forecast accuracy using metrics such as MAE, RMSE, and MAPE.\n",
    "* Visualize the predicted vs. actual values.\n",
    "#### Reporting Findings:\n",
    "* Summarize the results of the analysis, including the accuracy of different forecasting methods and insights gained from the time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320de1d4-e0e5-4129-a8b1-d0d8838c1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# Загрузка данных (например, датасет с временными рядами)\n",
    "data = pd.read_csv('supermarket_sales.csv', parse_dates=['Date'], index_col='Date')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611a668-2d05-4038-98bb-ddf3302531f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнение пропусков\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['value'])\n",
    "plt.title('Time Series Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae00c8f-e0ac-488f-98a8-9f298d03ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA модель\n",
    "arima_model = ARIMA(data['value'], order=(1, 1, 1))\n",
    "arima_result = arima_model.fit()\n",
    "data['ARIMA_Prediction'] = arima_result.predict(start=len(data)-100, end=len(data)-1, dynamic=False)\n",
    "\n",
    "# Экспоненциальное сглаживание (Holt-Winters)\n",
    "hw_model = ExponentialSmoothing(data['value'], seasonal='add', seasonal_periods=12)\n",
    "hw_result = hw_model.fit()\n",
    "data['HW_Prediction'] = hw_result.predict(start=len(data)-100, end=len(data)-1)\n",
    "\n",
    "# Визуализация предсказаний\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['value'], label='Actual')\n",
    "plt.plot(data['ARIMA_Prediction'], label='ARIMA Prediction')\n",
    "plt.plot(data['HW_Prediction'], label='Holt-Winters Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54ca1e-cd88-4191-999a-441a434e3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики для ARIMA\n",
    "arima_mae = mean_absolute_error(data['value'][-100:], data['ARIMA_Prediction'][-100:])\n",
    "arima_rmse = sqrt(mean_squared_error(data['value'][-100:], data['ARIMA_Prediction'][-100:]))\n",
    "print(f'ARIMA MAE: {arima_mae}, RMSE: {arima_rmse}')\n",
    "\n",
    "# Метрики для Holt-Winters\n",
    "hw_mae = mean_absolute_error(data['value'][-100:], data['HW_Prediction'][-100:])\n",
    "hw_rmse = sqrt(mean_squared_error(data['value'][-100:], data['HW_Prediction'][-100:]))\n",
    "print(f'Holt-Winters MAE: {hw_mae}, RMSE: {hw_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2868b2-dfe5-4c46-a9eb-4f7a3faa6f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9aa69-ad99-41ef-b31d-01a55525bf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3559352-a7f0-4a10-80ee-1982e14fc48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccceac1-4cbd-4c81-ada2-885e0f0e8ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3a398-c756-4250-86e5-de26fded1f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
