{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ea0d6b-b0e3-4112-91fe-cdf68af1555b",
   "metadata": {},
   "source": [
    "## Assignment 2, Data Mining\n",
    "\n",
    "Put all deliverables into github repository in your profile. Share link to google form 24 hours before defense. Defend by explaining deliverables and answering questions.\n",
    "Deliverables: .ipynb\n",
    "Google form: https://docs.google.com/forms/d/e/1FAIpQLSe0GyNdOYlvM1tX_I_CtlPod5jBf-ACLGdHYZq1gVZbUeBzIg/viewform?usp=sf_link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a83cb-4866-4932-8aa6-1865eef6f687",
   "metadata": {},
   "source": [
    "### Exercise 1: Feature Selection with SelectKBest\n",
    "\n",
    "Objective: Use SelectKBest from scikit-learn to select the top k features from a dataset.\n",
    "\n",
    "* 1.Load the Iris dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into features and target variable.\n",
    "\n",
    "* 3.Use SelectKBest with the chi2 score function to select the top 2 features.\n",
    "\n",
    "* 4.Print the selected feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e5cc9c-2d8a-4649-b4ae-3bc6741f4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = pd.DataFrame(iris.data, columns=iris.feature_names), iris.target\n",
    "\n",
    "# Select the top 2 features using chi-squared score\n",
    "selector = SelectKBest(score_func=chi2, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Print the selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected features:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abaa6fe-e44e-4611-aa84-2468257e0ce1",
   "metadata": {},
   "source": [
    "### Exercise 2: Feature Importance with Random Forest\n",
    "\n",
    "Objective: Use a Random Forest classifier to determine feature importance.\n",
    "\n",
    "* 1.Load the Wine dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train a Random Forest classifier on the training data.\n",
    "\n",
    "* 4.Extract and visualize feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ba802c-38ff-4ac8-804b-c88a784555a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Extract feature importances\u001b[39;00m\n\u001b[0;32m     19\u001b[0m importances \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m---> 20\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margsort(importances)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Visualize feature importances\u001b[39;00m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X, y = pd.DataFrame(wine.data, columns=wine.feature_names), wine.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=importances[indices], y=X.columns[indices])\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4107cb5-ae6e-4db4-87c8-8b0a736c5373",
   "metadata": {},
   "source": [
    "### Exercise 3: Recursive Feature Elimination (RFE)\n",
    "\n",
    "Objective: Use Recursive Feature Elimination (RFE) to select features and evaluate model performance.\n",
    "\n",
    "* 1.Load the Breast Cancer dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Use RFE with a Support Vector Machine (SVM) classifier to select features.\n",
    "\n",
    "* 4.Train an SVM model with the selected features and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cbf4d-2c91-40c7-995f-400f9d98c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = pd.DataFrame(cancer.data, columns=cancer.feature_names), cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use RFE with SVM to select features\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=svc, n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Train an SVM model with the selected features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "svc.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "y_pred = svc.predict(X_test_rfe)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26683b60-443b-496d-a00d-7d3c9cb0263a",
   "metadata": {},
   "source": [
    "### Exercise 4: L1 Regularization for Feature Selection\n",
    "\n",
    "Objective: Use L1 regularization (Lasso) for feature selection.\n",
    "\n",
    "* 1.Load the Diabetes dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Apply Lasso regression for feature selection.\n",
    "\n",
    "* 4.Train a model using selected features and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3f226-2a79-496e-b930-7f01fe98bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = pd.DataFrame(diabetes.data, columns=diabetes.feature_names), diabetes.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Lasso regression for feature selection\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Train a model using selected features\n",
    "selected_features = X.columns[lasso.coef_ != 0]\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "lasso.fit(X_train_selected, y_train)\n",
    "y_pred = lasso.predict(X_test_selected)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c99dda-94de-4d50-b57b-3fd5c87fde1f",
   "metadata": {},
   "source": [
    "## Classification Exercises\n",
    "\n",
    "### Exercise 1: Logistic Regression\n",
    "\n",
    "Objective: Build a logistic regression model to classify data.\n",
    "\n",
    "* 1.Load the Iris dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train a logistic regression model on the training set.\n",
    "\n",
    "* 4.Evaluate the model's performance on the test set using accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265eb97-e1b8-45ac-8b85-b2c5da72b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = pd.DataFrame(iris.data, columns=iris.feature_names), iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8af54-e567-4f2a-bfc6-4e4581cbdb1e",
   "metadata": {},
   "source": [
    "### Exercise 2: Support Vector Machine (SVM)\n",
    "\n",
    "Objective: Use an SVM classifier to classify data.\n",
    "\n",
    "* 1.Load the Breast Cancer dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train an SVM model on the training data.\n",
    "\n",
    "* 4.Evaluate the model's performance on the test data using accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a49193-e3a3-4451-89e2-1e93de1852a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = pd.DataFrame(cancer.data, columns=cancer.feature_names), cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35af69-6c5d-4150-848d-616d5d3d8d96",
   "metadata": {},
   "source": [
    "### Exercise 3: Decision Tree Classifier\n",
    "\n",
    "Objective: Build a decision tree classifier and visualize it.\n",
    "\n",
    "* 1.Load the Wine dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train a decision tree classifier on the training set.\n",
    "\n",
    "* 4.Visualize the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d6c4c-34e0-4d85-88af-d5a27f48ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X, y = pd.DataFrame(wine.data, columns=wine.feature_names), wine.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns)\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12234153-3c06-4be3-b5b6-1e03b26bc530",
   "metadata": {},
   "source": [
    "## Regression Exercises\n",
    "\n",
    "### Exercise 1: Linear Regression\n",
    "\n",
    "Objective: Build a linear regression model to predict a continuous target variable.\n",
    "\n",
    "* 1.Load the Boston Housing dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train a linear regression model on the training set.\n",
    "\n",
    "* 4.Evaluate the model's performance using mean squared error (MSE) and R-squared score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb4bbb-558c-41fc-a321-02d9d73b882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X, y = pd.DataFrame(boston.data, columns=boston.feature_names), boston.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da990bad-6bee-49da-aa39-b5f349056b2d",
   "metadata": {},
   "source": [
    "### Exercise 2: Ridge Regression\n",
    "\n",
    "Objective: Use Ridge regression to perform regularized linear regression.\n",
    "\n",
    "* 1.Load the Diabetes dataset from scikit-learn.\n",
    "\n",
    "* 2.Split the dataset into training and testing sets.\n",
    "\n",
    "* 3.Train a Ridge regression model on the training set.\n",
    "\n",
    "* 4.Evaluate the model's performance using mean squared error (MSE) and R-squared score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a6b44-3125-4375-8ee5-1e89bb024169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = pd.DataFrame(diabetes.data, columns=diabetes.feature_names), diabetes.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Ridge regression model\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = ridge_reg.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8d729-091a-424b-8e91-e2a3b37ea6d3",
   "metadata": {},
   "source": [
    "### Exercise 3: Decision Tree Regression\n",
    "\n",
    "Objective: Build a decision tree regression model and visualize it.\n",
    "\n",
    "* 1.Load the Boston Housing dataset from scikit-learn.\n",
    "  \n",
    "* 2.Split the dataset into training and testing sets.\n",
    "  \n",
    "* 3.Train a decision tree regressor on the training set.\n",
    "  \n",
    "* 4.Evaluate the model's performance using mean squared error (MSE).\n",
    "  \n",
    "* 5.Visualize the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045e1b8-f957-44c6-ba58-418531f408d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X, y = pd.DataFrame(boston.data, columns=boston.feature_names), boston.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a decision tree regressor\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = dt_regressor.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(dt_regressor, filled=True, feature_names=X.columns)\n",
    "plt.title(\"Decision Tree Regressor\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
