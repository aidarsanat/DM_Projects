{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1fd8ba0-eb96-4c8a-a567-b9eb14de6df6",
   "metadata": {},
   "source": [
    "## Assignment 1, Data Mining\n",
    "\n",
    "Put all deliverables into github repository in your profile. Share link to google form 24 hours before defense. Defend by explaining deliverables and answering questions.\n",
    "Deliverables: .ipynb\n",
    "Google form: https://docs.google.com/forms/d/e/1FAIpQLSe0GyNdOYlvM1tX_I_CtlPod5jBf-ACLGdHYZq1gVZbUeBzIg/viewform?usp=sf_link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64939b45-c7d7-4527-9d75-bec5622790dd",
   "metadata": {},
   "source": [
    "## Exercise 1: Loading Data with Pandas\n",
    "\n",
    "#### 1. Objective: Learn how to load and inspect datasets using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151a41e-4f2d-4eae-b4f1-b5471d48f778",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Import the Pandas library and load a CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a799a008-0f51-4b46-8ca8-c5252300f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('heart_failure_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f1ac7-c535-4915-bb94-c73d3e64dd8a",
   "metadata": {},
   "source": [
    "* Use the head(), tail(), and info() functions to inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b629d687-85d9-49de-95cf-20a9f890224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9e502b-037d-4e21-bda2-ca50e815ec15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2060</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>742000.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2413</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "294  62.0        0                        61         1                 38   \n",
       "295  55.0        0                      1820         0                 38   \n",
       "296  45.0        0                      2060         1                 60   \n",
       "297  45.0        0                      2413         0                 38   \n",
       "298  50.0        0                       196         0                 45   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "294                    1   155000.0               1.1           143    1   \n",
       "295                    0   270000.0               1.2           139    0   \n",
       "296                    0   742000.0               0.8           138    0   \n",
       "297                    0   140000.0               1.4           140    1   \n",
       "298                    0   395000.0               1.6           136    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "294        1   270            0  \n",
       "295        0   271            0  \n",
       "296        0   278            0  \n",
       "297        1   280            0  \n",
       "298        1   285            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f8f4c7-d3a3-4f15-b895-c8b2ff4de06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0847e4e-cc44-49e9-8114-7a4eec33505b",
   "metadata": {},
   "source": [
    "* Check for missing values and data types of each column using isnull() and dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61f3143-7465-4d87-83ad-5aede9796451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0d5984-33b3-4ef3-b0a2-87d384b2eeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         float64\n",
       "anaemia                       int64\n",
       "creatinine_phosphokinase      int64\n",
       "diabetes                      int64\n",
       "ejection_fraction             int64\n",
       "high_blood_pressure           int64\n",
       "platelets                   float64\n",
       "serum_creatinine            float64\n",
       "serum_sodium                  int64\n",
       "sex                           int64\n",
       "smoking                       int64\n",
       "time                          int64\n",
       "DEATH_EVENT                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba9799-1335-46dc-ba1f-56363fbd7a8c",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "\n",
    "* How do you load a CSV file into a Pandas DataFrame?\n",
    "\n",
    "You can use pd.read_csv('filename.csv') to load a CSV file into a DataFrame.\n",
    "\n",
    "* What information does the info() function provide about the dataset?\n",
    "\n",
    "It shows column names, number of non-null entries, and the data types of each column.\n",
    "\n",
    "* How can you identify missing values in the dataset?\n",
    "\n",
    "Use df.isnull().sum() to see how many missing values exist in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a74c00-33d8-43dc-a121-171dbc097bf3",
   "metadata": {},
   "source": [
    "## Exercise 2: Handling Missing Data\n",
    "\n",
    "#### 1. Objective: Practice techniques for handling missing data in a dataset.\n",
    "* Use different strategies to handle missing data:\n",
    "    1) Remove rows with missing values using dropna().\n",
    "    2) Fill missing values with the mean, median, or a specific value using fillna().\n",
    "    3) Use forward or backward filling (ffill() or bfill()) to fill missing data.\n",
    "* Compare the results of each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c89a0-2c1b-479a-ac02-dffc777cecf5",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Identify missing values in the dataset using isnull().sum()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327b3731-373f-4c25-87d1-112e462a298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa2a96-044b-42ae-82ea-f7bb07f85a38",
   "metadata": {},
   "source": [
    "* Use different strategies to handle missing data:\n",
    "    1) Remove rows with missing values using dropna().\n",
    "    2) Fill missing values with the mean, median, or a specific value using fillna().\n",
    "    3) Use forward or backward filling (ffill() or bfill()) to fill missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc0583d-61ad-496b-b0a0-47ba447b3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df_dropped = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62014639-93bc-4afc-8f39-7917fb3512e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df['creatinine_phosphokinase'] = df['creatinine_phosphokinase'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4b9224-48fd-4d17-af0e-6446b30e1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df.ffill(inplace=True)\n",
    "df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd2ad1a-65c5-49b1-87d2-3959c5da94c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb63b3d1-1454-4cc4-9d0d-30e45a60efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                         0\n",
      "anaemia                     0\n",
      "creatinine_phosphokinase    0\n",
      "diabetes                    0\n",
      "ejection_fraction           0\n",
      "high_blood_pressure         0\n",
      "platelets                   0\n",
      "serum_creatinine            0\n",
      "serum_sodium                0\n",
      "sex                         0\n",
      "smoking                     0\n",
      "time                        0\n",
      "DEATH_EVENT                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df1d7d-7dc3-4a0b-97a9-c401a2a39567",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* What strategy did you use to handle missing values, and why?\n",
    "\n",
    "Filling missing numerical values with the mean because it doesn't distort the distribution much.\n",
    "\n",
    "* How did filling missing values affect the dataset?\n",
    "\n",
    "It prevented the loss of data while filling gaps with a reasonable estimate.\n",
    "\n",
    "* When might it be more appropriate to drop rows with missing values instead of filling them?\n",
    "\n",
    "When the percentage of missing data is small, or when filling the values would introduce bias or inaccuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb8753-9533-4404-bd34-3ba118aa5a91",
   "metadata": {},
   "source": [
    "## Exercise 3: Data Transformation\n",
    "\n",
    "#### 1. Objective: Transform data to prepare it for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c2776-b63f-4408-9bf0-185b000725eb",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "   \n",
    "* Normalize numerical features using Min-Max scaling or Z-score standardization with sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301337bf-8812-44c1-a206-b6cf07f5a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Normalize numerical features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['age', 'creatinine_phosphokinase', 'platelets', 'serum_creatinine', 'serum_sodium']] = scaler.fit_transform(df[['age', 'creatinine_phosphokinase', 'platelets', 'serum_creatinine', 'serum_sodium']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ed0ad-a47d-49ae-a0ad-576aa5b273bd",
   "metadata": {},
   "source": [
    "* Encode categorical variables using one-hot encoding with pd.get_dummies() or sklearn.preprocessing.OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3340d03a-8a8a-447f-b3cd-c6ea5faf9cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
      "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n",
      "       'DEATH_EVENT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afbc34d7-02f5-4662-8a31-9429b439d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if columns exist before encoding\n",
    "if 'sex' in df.columns and 'smoking' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['sex', 'smoking'], drop_first=True)\n",
    "else:\n",
    "    print(\"Columns 'sex' or 'smoking' are not in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c1ed495-15b4-49ed-bc5c-b48f805ad960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sex_1', 'smoking_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ab7e2-32da-47c4-979d-2aaa2c65bebe",
   "metadata": {},
   "source": [
    "* Use pd.cut() to bin continuous variables into discrete intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c589b23c-cb0c-4884-85f1-9fa5c9b1c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin continuous variables (if necessary)\n",
    "df['ejection_fraction_bins'] = pd.cut(df['ejection_fraction'], bins=[0, 40, 60, 100], labels=['Low', 'Medium', 'High'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacb58b-72e3-4d44-9b7e-b4f2402e3d73",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* What is the difference between normalization and standardization?\n",
    "\n",
    "Normalization scales data between 0 and 1, while standardization transforms data to have a mean of 0 and standard deviation of 1.\n",
    "\n",
    "* How does one-hot encoding transform categorical variables?\n",
    "\n",
    "It converts categorical columns into binary columns for each category, assigning a 1 where the category is present and 0 otherwise.\n",
    "\n",
    "* Why might you want to bin continuous variables into categories?\n",
    "\n",
    "Binning can simplify data and make patterns more apparent, especially for models that don't assume linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c588f05-7399-47b7-9218-023e95dd4dc5",
   "metadata": {},
   "source": [
    "## Exercise 4: Feature Engineering\n",
    "\n",
    "#### 1. Objective: Create new features to improve the predictive power of a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4a871-21c5-4b10-8f77-bb976e63f3f7",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Create new features by combining or transforming existing features (e.g., adding interaction terms or polynomial features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a1d70c-abfb-44b6-a781-6ba757a9a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_platelets_interaction'] = df['age'] * df['platelets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbe28d1-c8d6-43e1-a243-3b0e92e7416d",
   "metadata": {},
   "source": [
    "* Extract date-based features (e.g., year, month, day) from datetime columns using pd.to_datetime() and dt accessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01491e54-7ada-49cd-a0d9-b8be4f4c3aa4",
   "metadata": {},
   "source": [
    "* Use domain knowledge to engineer features that might be useful for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea52d1-998d-43ff-9692-dbfb7bc86944",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* What new features did you create, and why?\n",
    "\n",
    "For instance, the \"age_to_ejection_fraction\" ratio because it may correlate with the target.\n",
    "\n",
    "* How did the new features improve the dataset?\n",
    "\n",
    "It added more information for model training.\n",
    "\n",
    "* How can date-based features be useful in a dataset?\n",
    "\n",
    "They can capture trends over time or seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00b3a2-8976-4668-93b7-769a5bf3d953",
   "metadata": {},
   "source": [
    "## Exercise 5: Data Cleaning\n",
    "\n",
    "#### 1. Objective: Clean data to ensure it's ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df675dc1-7be3-42ff-8587-b4200b755402",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Remove duplicate rows using drop_duplicates()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fc75887-abab-4255-aab9-1874feb97b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffa215-5aa6-4b0c-bb90-b3bcc6fbb281",
   "metadata": {},
   "source": [
    "* Detect and remove outliers using the Z-score method or the IQR method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a435122-eb2a-4b96-9493-d4dc3c310239",
   "metadata": {},
   "source": [
    "1) Z-score method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a539196-b8a8-4751-b2fa-17460b93ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = df[(np.abs(stats.zscore(df[['age', 'creatinine_phosphokinase', 'platelets', 'serum_creatinine', 'serum_sodium']])) < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b3495-8805-4213-a1d9-3ddb46156617",
   "metadata": {},
   "source": [
    "Correct inconsistencies in categorical data (e.g., standardizing text formats or merging similar categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6800109-722e-4171-a2fb-b9400fc97436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
      "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium', 'time', 'DEATH_EVENT',\n",
      "       'sex_1_False', 'sex_1_True', 'smoking_1_False', 'smoking_1_True',\n",
      "       'ejection_fraction_bins', 'age_platelets_interaction'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b008a3-27f7-43f1-88cf-ce31926275f8",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* How did you identify and handle duplicate rows in the dataset?\n",
    "\n",
    "Use df.duplicated() to find duplicates and remove them with drop_duplicates().\n",
    "\n",
    "* What method did you use to detect and remove outliers, and why?\n",
    "\n",
    "Z-score to remove points further than 3 standard deviations from the mean.\n",
    "\n",
    "* How did you address inconsistencies in categorical data?\n",
    "\n",
    "Standardized categories by converting all text to lowercase or merging similar categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993859bc-88e3-4ad2-966a-c16c40c11942",
   "metadata": {},
   "source": [
    "## Exercise 6: Splitting Data into Training and Testing Sets\n",
    "\n",
    "#### 1. Objective: Prepare the data for model training by splitting it into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116583bc-5800-4b99-aff3-89163d638b30",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Use sklearn.model_selection.train_test_split() to split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31cc4fe1-2b94-432f-be8a-19f0995373f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df.apply(lambda row: 'male' if row['sex_1_True'] else 'female', axis=1)\n",
    "df.drop(columns=['sex_1_False', 'sex_1_True'], inplace=True)\n",
    "\n",
    "df['smoking'] = df.apply(lambda row: 'yes' if row['smoking_1_True'] else 'no', axis=1)\n",
    "df.drop(columns=['smoking_1_False', 'smoking_1_True'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8a40b95-2854-4c33-a124-ae45a6b213c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd5ec2-0eb1-4019-a665-9d99176f8b49",
   "metadata": {},
   "source": [
    "* Ensure that the target variable is correctly separated from the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bef56-6dbf-4ff4-8f6d-907abc71d2e1",
   "metadata": {},
   "source": [
    "* Explore the impact of different train-test split ratios (e.g., 70-30, 80-20) on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51730a97-9011-4f01-8c5b-4cddcb21e61d",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* How do you split a dataset into training and testing sets in Python?\n",
    "\n",
    "Use train_test_split() from sklearn to separate data into training and testing sets.\n",
    "\n",
    "* What considerations should you keep in mind when choosing a train-test split ratio?\n",
    "\n",
    "The split should balance enough training data for learning and enough test data to evaluate generalization.\n",
    "\n",
    "* How does the size of the training set impact the model's ability to generalize?\n",
    "\n",
    "A larger training set helps the model learn patterns but might leave less data to assess performance accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bee8b4-9764-4245-89c2-901457e39850",
   "metadata": {},
   "source": [
    "## Exercise 7: Data Preprocessing Pipeline\n",
    "\n",
    "#### 1. Objective: Build a preprocessing pipeline to automate the data preparation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf5b78-4365-451f-b7f0-e233046840a7",
   "metadata": {},
   "source": [
    "#### 2. Steps:\n",
    "\n",
    "* Use sklearn.pipeline.Pipeline to create a pipeline that includes steps such as missing value imputation, feature scaling, and encoding categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14cac7bd-0222-4032-9299-386032dda4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
      "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium', 'time', 'ejection_fraction_bins',\n",
      "       'age_platelets_interaction', 'sex', 'smoking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c148dd78-590e-4e3e-b190-38c5ccfd886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
      "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium', 'time', 'DEATH_EVENT',\n",
      "       'ejection_fraction_bins', 'age_platelets_interaction', 'sex',\n",
      "       'smoking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2593d3d1-13f7-4345-8f15-a2fe973249c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
      "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
      "       'serum_creatinine', 'serum_sodium', 'time', 'DEATH_EVENT',\n",
      "       'ejection_fraction_bins', 'age_platelets_interaction', 'sex',\n",
      "       'smoking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "756ab531-01de-4b48-a84c-47f77afad098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83        40\n",
      "           1       0.62      0.47      0.53        17\n",
      "\n",
      "    accuracy                           0.75        57\n",
      "   macro avg       0.71      0.67      0.68        57\n",
      "weighted avg       0.74      0.75      0.74        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "numeric_features = ['age', 'creatinine_phosphokinase', 'platelets', 'serum_creatinine', 'serum_sodium']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create a pipeline for categorical features\n",
    "categorical_features = ['sex', 'smoking']  # Adjust as needed based on your encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the full pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f38ba-2a51-461b-9ecb-b3295afbcf9a",
   "metadata": {},
   "source": [
    "* Fit the pipeline to the training data and transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0386644b-65ac-44f4-9c07-bef6c605654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30903c7-0c73-4d4c-ab92-27523557938f",
   "metadata": {},
   "source": [
    "* Integrate the preprocessing pipeline with a machine learning model for end-to-end training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "290c2a09-0372-43e7-8656-8cfa5d9c0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b34857eb-8846-4194-958e-c8554b9770ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83        40\n",
      "           1       0.62      0.47      0.53        17\n",
      "\n",
      "    accuracy                           0.75        57\n",
      "   macro avg       0.71      0.67      0.68        57\n",
      "weighted avg       0.74      0.75      0.74        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20da682-3f2b-4999-8639-358d66e82a5c",
   "metadata": {},
   "source": [
    "#### 3. Questions:\n",
    "* What are the benefits of using a preprocessing pipeline?\n",
    "\n",
    "Automation and consistency in data transformation.\n",
    "\n",
    "* How does the pipeline ensure consistency between training and test data transformations?\n",
    "\n",
    "It applies the same transformations (e.g., scaling, encoding) to both datasets.\n",
    "\n",
    "* How can you extend the pipeline to include additional preprocessing steps?\n",
    "\n",
    "Add more transformers in the pipeline, such as feature selection or interaction terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
